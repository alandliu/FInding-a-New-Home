{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54e2ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import StandardScaler\\nsc = StandardScaler()\\nx_train = sc.fit_transform(x_train)\\nx_test = sc.fit_transform(x_test)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from habitablePlanets import habitable_planets\n",
    "\n",
    "exoplanets = pd.read_csv(\"exoplanets3.csv\", sep=\",\")\n",
    "training_data = np.array(exoplanets[:])\n",
    "\n",
    "'''print(training_data.shape)\n",
    "print(training_data)'''\n",
    "\n",
    "habitable_x = np.array([np.array(training_data[0, :])])\n",
    "habitable_y = np.array([0])\n",
    "uninhabitable_x = np.array([np.array(training_data[0, :])])\n",
    "uninhabitable_y = np.array([0])\n",
    "\n",
    "for i in training_data:\n",
    "    if i[0] in habitable_planets:\n",
    "        habitable_x = np.append(habitable_x, np.array([np.array(i)]), axis = 0)\n",
    "        habitable_y = np.append(habitable_y, 1)\n",
    "        \n",
    "\n",
    "for i in training_data:\n",
    "    if i[0] not in habitable_planets:\n",
    "        uninhabitable_x = np.append(uninhabitable_x, np.array([np.array(i)]), axis = 0)\n",
    "        uninhabitable_y = np.append(uninhabitable_y, 0)\n",
    "\n",
    "        \n",
    "training_x = np.append(habitable_x[:, 1:], uninhabitable_x[:, 1:], axis = 0)\n",
    "training_y = np.append(habitable_y, uninhabitable_y, axis = 0)\n",
    "\n",
    "habitable_x = habitable_x[:, 1:]\n",
    "uninhabitable_x = uninhabitable_x[:, 1:]\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "\n",
    "training_x = np.asarray(training_x).astype(np.float32)\n",
    "training_x = np.where(np.isnan(training_x), ma.array(training_x, mask=np.isnan(training_x)).mean(axis=0), training_x)\n",
    "\n",
    "oversample = SMOTE()\n",
    "x_res, y_res = oversample.fit_resample(training_x, training_y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#feature scaling\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db55fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694718763417776\n",
      "Wall time: 326 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aland Liu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs')\n",
    "LogReg.fit(x_train, y_train)\n",
    "print(LogReg.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c8f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = LogReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94c2778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[713 150]\n",
      " [121 763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       863\n",
      "           1       0.84      0.86      0.85       884\n",
      "\n",
      "    accuracy                           0.84      1747\n",
      "   macro avg       0.85      0.84      0.84      1747\n",
      "weighted avg       0.85      0.84      0.84      1747\n",
      "\n",
      "0.8448769318832284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03560521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#nonsynthetic data\n",
    "\n",
    "x_test = np.array([np.array(training_data[0, 1:])])\n",
    "y_test = np.array([0])\n",
    "\n",
    "hab_lim = 20\n",
    "cur_hab = 1\n",
    "\n",
    "for i in training_data:\n",
    "    if cur_hab >= hab_lim:\n",
    "        break\n",
    "    if i[0] in habitable_planets:\n",
    "        y_test = np.append(y_test, 1)\n",
    "        cur_hab += 1\n",
    "    else:\n",
    "        y_test = np.append(y_test, 0)\n",
    "    x_test = np.append(x_test, np.array([np.array(i[1:])]), axis = 0)\n",
    "\n",
    "x_test = np.asarray(x_test).astype(np.float32)\n",
    "x_test = np.where(np.isnan(x_test), ma.array(x_test, mask=np.isnan(x_test)).mean(axis=0), x_test)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "y_test = np.where(np.isnan(y_test), ma.array(y_test, mask=np.isnan(y_test)).mean(axis=0), y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4c9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1233  183]\n",
      " [   2   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.87      0.93      1416\n",
      "         1.0       0.09      0.89      0.16        19\n",
      "\n",
      "    accuracy                           0.87      1435\n",
      "   macro avg       0.54      0.88      0.54      1435\n",
      "weighted avg       0.99      0.87      0.92      1435\n",
      "\n",
      "0.8710801393728222\n",
      "Wall time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = LogReg.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e89bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
